{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "## Vocabs \n",
    "* `Feature Vector` - The inputs of the data for the model `O(x) E R ** d`\n",
    "* `Target Vector` - The output of the data for the model `W E R** d`\n",
    "* `x Matrix` - The matrix of all the features/inputs in the model\n",
    "* `Y Matrix` - The matrix of all the target/output values in the model \n",
    "* `Training Data Set` - set of data to be trained\n",
    "* `Validation Data Set` - set of data to be validated with for feedback\n",
    "* `Test Data Set` - set of data to be tested on\n",
    "* `Over Sampling` - When one type of data are more\n",
    "* ## Types of Scaling\n",
    "* * `Standard Scaler` - Scales the data for proper training\n",
    "* ## Types of Oversampling\n",
    "* * `Random Over Sampler` - corrects the oversampling of the data\n",
    "* ## Types of Learningabels are provided by the programer to the model for classification\n",
    "* * * `Features` - \n",
    "* * `Supervised Learning` - A type of learning where l\n",
    "* * * * `Qualitative` - categorical data \n",
    "* * * * * `Matrix Formation`\n",
    "* * * * * `Integer Formation` \n",
    "* * * * `Quantitative` - numerical Value\n",
    "* * ### Types of Prediction \n",
    "* * * `Clasification` = prediciting the classes/labels of data\n",
    "* * * * `Binary Classification` - making only two classes/labels for the classification `x -> y -> E {+1 , -1}/{0 , 1}`\n",
    "* * * * `Multiclass Classification` - making classes more than two `x -> y-> E {N}`\n",
    "* * * * `Multilabel Classification` - making labels more than two `x -> y-> E {N/R}`\n",
    "* * * * `Imbalanced Classification` - one class having more predictions than other `x^ -> y^ -> E {R} , x -> y-> E {R}`\n",
    "* * * `Regressions` - prediciting continous values `x -> y-> E {R}`\n",
    "* * * * `Linear Regression` - using `f(y) = mx + b as classifier`\n",
    "* * * * `Logistic Regression` - using `f(y) = s(y) = (1 / (1 - (e ** x)))`\n",
    "* * * `Rnaking` - prediciting as contious values `{R} -> f -> {R}`\n",
    "* * * `Structured Predicition` - y is an object which is built from parts `\"string\" -> f -> \"string\"`\n",
    "* * ### Types of Models\n",
    "* * * `Models` - models to train\n",
    "* * * * `KNN(K Nearest Neighbours)` - predicts the data comapring with the k nearest neighbours of the data set\n",
    "* * * * * `k` = number of neighbours to be compared \n",
    "* * * * * `Euclidean Distance` - The distance between two coordinates on a number line  D = `((((x_1 - x_2)) ** 2) + (((y_1 - y_2)) ** 2))**(1 / 2)`\n",
    "* * * * `Decision Tree Classifier` - predicts with the help of desicion tree (2 labels)\n",
    "* * * * * `Entropy` - The varibale used to determine the best fit of the condition\n",
    "* * * * `Decision Tree Regressor` - preditics with the help of decision tree (more than 2 labels)\n",
    "* * * * * `Variance Reduction` - calculating variance for the best fit of the condition\n",
    "* * * * `Random Forest Classisifier` - uses random decision tree to reduce vulanarability of the variance\n",
    "* * * * * `Bootstrapping` - randomly selecting features for decision tree  \n",
    "* * * * `Naive Bayes` - Uses the bayes theorem to predict \n",
    "* * * * * `posterirr` - the probablity to be calculated\n",
    "* * * * * `likelihood` - the inverse probablity\n",
    "* * * * * `prior` - the alpha probablity \n",
    "* * * * * `evidence`  - the beta probablity\n",
    "* * * * * `Bayes Theorem` - `P(a/b) = (P(b/a) * p(a)) / P(b)`\n",
    "* * * * * `argBayes Rule` - `P(c_k/x_1 , x_2 , x_3 , ... , x_n) = P(c_k) n||i = 1 p((x_i/c_k))`\n",
    "* * * * `Logistic Regression` - using sigmoid function to predict \n",
    "* * * * * `Sigmoid Functions` - `s(x) = (1 / (1 - (e ** x)))`\n",
    "* * * * `Support Vector Machines(SVM)` - uses projections to predict    \n",
    "* * `Unsupervised Learning` - A type of learning where labels are generated by the model itself for classification\n",
    "* * `Rienforcment Learning` - A type of learning where reward is given to the model for every correct predition and nothing for wrong predition\n",
    "* ## Metrics Of Performance\n",
    "* * `Loss - The difference between the validation tests and the training test \n",
    "* * * `Linear Loss` - `loss = sum(|y_real - y_predicted|)`\n",
    "* * * `Quadratic Loss` - `loss = sum((y_real - y_predicted)**2)`\n",
    "* * * `Binary Cross Entropy Loss` - `loss = (-1 / N)*(sum(((y_real) * log(y_predicted))) + ((1 - y_real) * log(1 - y_predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4 (main, Nov 29 2022, 20:00:25) [GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
